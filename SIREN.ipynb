{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model / Data Parameters\nnum_classes = 10\ninput_shape = (28,28,1)\n# Data Split by Train & Test\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()","execution_count":2,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling of data\nx_train = x_train.astype(\"float32\")/255\nx_test = x_test.astype(\"float32\")/255\n# Check if the shape is (28,28,1)\nx_train = np.expand_dims(x_train,-1)\nx_test = np.expand_dims(x_test, -1)\nprint(\"x_train shape:\", x_train.shape)\nprint(x_train.shape[0], \"train samples\")\nprint(x_test.shape[0], \"test samples\")\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","execution_count":3,"outputs":[{"output_type":"stream","text":"x_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        layers.Conv2D(32, kernel_size=(3, 3), activation=tf.math.sin, kernel_initializer=\"he_uniform\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(64, kernel_size=(3, 3), activation=tf.math.sin, kernel_initializer=\"he_uniform\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(128, kernel_size=(3, 3), activation=tf.math.sin, kernel_initializer=\"he_uniform\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation=\"softmax\"),\n    ]\n)\n\nmodel.summary()","execution_count":10,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 3, 3, 128)         73856     \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 1, 1, 128)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 128)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 93,962\nTrainable params: 93,962\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 15\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":11,"outputs":[{"output_type":"stream","text":"Epoch 1/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.3633 - accuracy: 0.8933 - val_loss: 0.0917 - val_accuracy: 0.9750\nEpoch 2/15\n422/422 [==============================] - 25s 60ms/step - loss: 0.1271 - accuracy: 0.9616 - val_loss: 0.0587 - val_accuracy: 0.9813\nEpoch 3/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.0936 - accuracy: 0.9713 - val_loss: 0.0516 - val_accuracy: 0.9832\nEpoch 4/15\n422/422 [==============================] - 25s 60ms/step - loss: 0.0740 - accuracy: 0.9778 - val_loss: 0.0467 - val_accuracy: 0.9858\nEpoch 5/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 0.0432 - val_accuracy: 0.9878\nEpoch 6/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.0409 - val_accuracy: 0.9875\nEpoch 7/15\n422/422 [==============================] - 30s 71ms/step - loss: 0.0504 - accuracy: 0.9842 - val_loss: 0.0374 - val_accuracy: 0.9880\nEpoch 8/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.0390 - val_accuracy: 0.9880\nEpoch 9/15\n422/422 [==============================] - 26s 61ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.0427 - val_accuracy: 0.9872\nEpoch 10/15\n422/422 [==============================] - 25s 60ms/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 0.0398 - val_accuracy: 0.9892\nEpoch 11/15\n422/422 [==============================] - 25s 60ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 0.0356 - val_accuracy: 0.9880\nEpoch 12/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: 0.0387 - val_accuracy: 0.9892\nEpoch 13/15\n422/422 [==============================] - 25s 60ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.0363 - val_accuracy: 0.9885\nEpoch 14/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.0279 - accuracy: 0.9911 - val_loss: 0.0352 - val_accuracy: 0.9900\nEpoch 15/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.0305 - accuracy: 0.9898 - val_loss: 0.0407 - val_accuracy: 0.9892\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f856474fb10>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss:\", score[0]*100)\nprint(\"Test accuracy:\", score[1]*100)","execution_count":13,"outputs":[{"output_type":"stream","text":"Test loss: 4.423553496599197\nTest accuracy: 98.71000051498413\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Setup for `Relu`"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1 = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation=\"softmax\"),\n    ]\n)\n\nmodel_1.summary()","execution_count":5,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 3, 3, 128)         73856     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 1, 1, 128)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 128)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 93,962\nTrainable params: 93,962\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 15\n\nmodel_1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel_1.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":7,"outputs":[{"output_type":"stream","text":"Epoch 1/15\n422/422 [==============================] - 25s 60ms/step - loss: 0.5017 - accuracy: 0.8488 - val_loss: 0.0938 - val_accuracy: 0.9730\nEpoch 2/15\n422/422 [==============================] - 24s 57ms/step - loss: 0.1558 - accuracy: 0.9544 - val_loss: 0.0677 - val_accuracy: 0.9803\nEpoch 3/15\n422/422 [==============================] - 25s 59ms/step - loss: 0.1208 - accuracy: 0.9637 - val_loss: 0.0592 - val_accuracy: 0.9833\nEpoch 4/15\n422/422 [==============================] - 24s 58ms/step - loss: 0.0954 - accuracy: 0.9706 - val_loss: 0.0480 - val_accuracy: 0.9862\nEpoch 5/15\n422/422 [==============================] - 24s 57ms/step - loss: 0.0836 - accuracy: 0.9751 - val_loss: 0.0519 - val_accuracy: 0.9853\nEpoch 6/15\n422/422 [==============================] - 25s 58ms/step - loss: 0.0751 - accuracy: 0.9776 - val_loss: 0.0453 - val_accuracy: 0.9878\nEpoch 7/15\n422/422 [==============================] - 24s 56ms/step - loss: 0.0643 - accuracy: 0.9808 - val_loss: 0.0451 - val_accuracy: 0.9883\nEpoch 8/15\n422/422 [==============================] - 24s 57ms/step - loss: 0.0618 - accuracy: 0.9810 - val_loss: 0.0561 - val_accuracy: 0.9840\nEpoch 9/15\n422/422 [==============================] - 24s 56ms/step - loss: 0.0545 - accuracy: 0.9832 - val_loss: 0.0437 - val_accuracy: 0.9887\nEpoch 10/15\n422/422 [==============================] - 24s 56ms/step - loss: 0.0484 - accuracy: 0.9845 - val_loss: 0.0446 - val_accuracy: 0.9892\nEpoch 11/15\n422/422 [==============================] - 24s 58ms/step - loss: 0.0457 - accuracy: 0.9852 - val_loss: 0.0433 - val_accuracy: 0.9885\nEpoch 12/15\n422/422 [==============================] - 24s 56ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.0420 - val_accuracy: 0.9883\nEpoch 13/15\n422/422 [==============================] - 24s 57ms/step - loss: 0.0419 - accuracy: 0.9871 - val_loss: 0.0401 - val_accuracy: 0.9892\nEpoch 14/15\n422/422 [==============================] - 24s 58ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.0427 - val_accuracy: 0.9902\nEpoch 15/15\n422/422 [==============================] - 24s 56ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0436 - val_accuracy: 0.9895\n","name":"stdout"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f85647073d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_1 = model_1.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss:\", score_1[0]*100)\nprint(\"Test accuracy:\", score_1[1]*100)","execution_count":15,"outputs":[{"output_type":"stream","text":"Test loss: 4.5937638729810715\nTest accuracy: 98.8099992275238\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** \n\nThis network performed far better than the original one with `relu` activations. This network achieved much lower loss `(~0.25 vs ~0.26)` on the test set. The test accuracy is also much better `(~99 vs ~991xx)`"},{"metadata":{},"cell_type":"markdown","source":"## CIFAR-10"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model / data parameters\nnum_classes = 10\ninput_shape = (32, 32, 1)\n\n\n# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n\n# Scale images to the [0, 1] range\nx_train = x_train.astype(\"float32\") / 255\nx_test = x_test.astype(\"float32\") / 255\n\nprint(\"x_train shape:\", x_train.shape)\nprint(x_train.shape[0], \"train samples\")\nprint(x_test.shape[0], \"test samples\")\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","execution_count":16,"outputs":[{"output_type":"stream","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 4s 0us/step\nx_train shape: (50000, 32, 32, 3)\n50000 train samples\n10000 test samples\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"This example has been taken from the old keras [website](https://keras.io/examples/cifar10_cnn/) and the following modifications were done:\n\n1. Change activation function from `relu` to `sin`\n2. Change initializer from `glorot_uniform` to `he_uniform`"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential()\nmodel.add(layers.Conv2D(32,\n                 (3, 3),\n                 padding='same',\n                 kernel_initializer=\"he_uniform\",\n                 activation=tf.math.sin,\n                 input_shape=x_train.shape[1:]))\nmodel.add(layers.Conv2D(32,\n                 (3, 3),\n                 kernel_initializer=\"he_uniform\",\n                 activation=tf.math.sin))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(64,\n                 (3, 3),\n                 padding='same',\n                 kernel_initializer=\"he_uniform\",\n                 activation=tf.math.sin))\nmodel.add(layers.Conv2D(64,\n                 (3, 3),\n                 kernel_initializer=\"he_uniform\",\n                 activation=tf.math.sin))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, kernel_initializer=\"he_uniform\", activation=tf.math.sin))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(num_classes, activation=\"softmax\"))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=25\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** \n\nEven without any `augmentation`, this network achieved the same validation accuracy `(~74%-75%)` whereas heavy augmentation is used in the original implementation. Although you can argue that with augmentation the network would take much more time to generalize as in the case of the original implementation, I would say that same holds for `overfitting`. The network isn't that bad in this case. "}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}